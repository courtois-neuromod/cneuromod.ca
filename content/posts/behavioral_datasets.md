---
title: "More than brain scans: CNeuroMod stimuli datasets"
description: "Yes! CNeuroMod comprises two stimuli datasets - and you can help ensure they are of the top quality!"
date: 2022-01-24 
author: "Valentina Borghesani"
image: "behavioral_datasets/datasets.png"
draft: False
tags: ["release"]
---

Do you know what experimental psychology, cognitive neuroimaging, and machine learning have in common? They need to probe biological and/or artificial agents with appropriate stimuli to gather insights on how tasks and scenarios are represented and processed. Thus empirical efforts in all three fields greatly benefit from large databases of stimuli controlled for key variables (e.g., psycholinguistic features) yet ecologically valid (i.e., similar enough to those encountered outside the laboratory). Within CNeuromod, we are currenlty creating and curating two databases of stimuli that we hope will become useful tools for the community.

![](triplets.png)

The first one, which we call **triplets**, is a words database. Specifically it targets semantic  (i.e., conceptual) representations as accessed via language thanks to a three-terms semantic associative task: which of two words is more closely associated with a given target (e.g., _is lemon closer to squeezer or sour?_). We generated more than 10k of triplets, and more than 2k have been behaviorally validated on Mechanical Turk: how do human raters solve each triplet? The full dataset will be release soon, meanwhile, you can refer to: 
_Borghesani, V. Armoza, J., Bellec, P. & Brambati S. (2021) The Triplets Task: a open, large scale, curated benchmark for biological and artificial semantic representations (in the making). Society for the Neurobiology of Language - [video abstract](https://youtu.be/LVWjHUXsrEQ)_ 

![](images10k.png)

The second dataset is made of more than 10k of ecologically valid, free from copy-rights limits images. You guest it: we call it **images10k**. Behavioral validation of the appropriate label (e.g., _is that a guitar or banjo?_) and category (e.g., _is that a bird or a mammal?_) for each image is about to start on the citizen science platform Zooniverse. To learn more about it, you can watch [this presentation](https://www.youtube.com/watch?t=1084&v=uwagyJIEBKY&feature=youtu.be) or read the additional information on [the official website](https://www.zooniverse.org/projects/vborghesani/you-see-it-you-name-it). And yes: if you want to help out psychologist, neuroscientists, and computer scientists with a few keystrokes, you can label some image!

Many thanks to Fran√ßois Nadeau and Samie-Jade Allard for the preparation of the image stimuli and Jonathan Armoza for the word ones! We also would like to acknowledge the help and support of the Zooniverse team and of all the raters/labelers out there: thanks for ensuring we produce and release the best datasets possible!  
